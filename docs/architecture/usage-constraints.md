# Usage Constraints & Data Governance Design

**Version:** PRD v2.2  
**Date:** 2026-02-05  
**Status:** Design Complete

---

## The Problem

In regulated industries (healthcare, finance, legal), data can be:
- ‚úÖ High quality and expert-approved
- ‚ùå But legally prohibited from certain uses

**Example:** Mammogram with patient health information (PHI)
- Expert radiologist approves accuracy
- HIPAA prohibits storing PHI in model weights (training)
- But CAN show as few-shot example (ephemeral, not persisted)

**Previous design only had:** `status` (unlabeled/labeled/rejected)  
**Missing:** Governance rules about what approved data can be used for

---

## The Solution: Two Orthogonal Dimensions

### Dimension 1: Status (Quality Gate)
**Question:** Is this data correct and approved?

| Value | Meaning |
|-------|---------|
| `unlabeled` | Pending expert review |
| `labeled` | Approved, ready for use |
| `rejected` | Incorrect, excluded |
| `flagged` | Needs additional review |

### Dimension 2: Usage Constraints (Governance)
**Question:** What can this approved data be used for?

| Field | Type | Purpose |
|-------|------|---------|
| `allowed_uses` | ARRAY<STRING> | Permitted usage types |
| `prohibited_uses` | ARRAY<STRING> | Explicitly forbidden uses |
| `usage_reason` | TEXT | Compliance/business justification |
| `data_classification` | STRING | public, internal, confidential, restricted |

---

## Usage Types

| Type | Persistence | Description |
|------|-------------|-------------|
| **`training`** | Permanent | Embedded in model weights via fine-tuning |
| **`validation`** | Permanent | Used in train/val split, influences training |
| **`evaluation`** | Temporary | Benchmark scoring, not stored |
| **`few_shot`** | Ephemeral | Shown at inference, then discarded |
| **`testing`** | Temporary | Human QA/inspection only |

---

## Real-World Scenarios

### Scenario 1: Mammogram with PHI (Healthcare/HIPAA)

**Data:** Patient mammogram image with diagnosis  
**Status:** `labeled` (expert radiologist approved)  
**Constraints:**
```json
{
  "allowed_uses": ["few_shot", "testing", "evaluation"],
  "prohibited_uses": ["training", "validation"],
  "usage_reason": "Contains identifiable patient data (PHI) - HIPAA compliance prohibits storing in model weights",
  "data_classification": "restricted"
}
```

**What This Enables:**
- ‚úÖ Show as few-shot example to guide model at inference
- ‚úÖ Use for manual testing by radiologists
- ‚úÖ Use for evaluation (measuring model accuracy)
- ‚ùå Cannot fine-tune model with this data
- ‚ùå Cannot use in validation set

**Why:** HIPAA allows temporary use (few-shot, eval) but prohibits permanent storage in model weights.

---

### Scenario 2: Synthetic Training Data (No Restrictions)

**Data:** AI-generated synthetic examples  
**Status:** `labeled`  
**Constraints:**
```json
{
  "allowed_uses": ["training", "validation", "evaluation", "few_shot", "testing"],
  "prohibited_uses": [],
  "usage_reason": "Synthetic data generated for training - no restrictions",
  "data_classification": "internal"
}
```

**What This Enables:**
- ‚úÖ Use everywhere without limitations

---

### Scenario 3: Proprietary Client Data (NDA/Confidentiality)

**Data:** Client trade secrets, IP, confidential business data  
**Status:** `labeled`  
**Constraints:**
```json
{
  "allowed_uses": ["training", "validation"],
  "prohibited_uses": ["few_shot", "evaluation"],
  "usage_reason": "Client NDA - cannot expose in runtime examples that might be logged or traced",
  "data_classification": "confidential"
}
```

**What This Enables:**
- ‚úÖ Fine-tune model (weights are protected, not exposed)
- ‚úÖ Use in validation set (stays in secure pipeline)
- ‚ùå Cannot show as few-shot example (might leak in agent traces)
- ‚ùå Cannot use in public benchmarks

**Why:** Model weights are secure, but runtime examples can leak in logs/traces.

---

### Scenario 4: Test Set (Data Hygiene)

**Data:** Held-out test set for final evaluation  
**Status:** `labeled`  
**Constraints:**
```json
{
  "allowed_uses": ["evaluation", "testing"],
  "prohibited_uses": ["training", "validation", "few_shot"],
  "usage_reason": "Held-out test set - must not be seen during training to prevent data leakage",
  "data_classification": "internal"
}
```

**What This Enables:**
- ‚úÖ Use for final evaluation
- ‚úÖ Use for manual testing
- ‚ùå Cannot train on this data (data leakage)
- ‚ùå Cannot show as few-shot (would contaminate results)

**Why:** Maintaining clean train/test split prevents overfitting.

---

## Enforcement Points

### TRAIN Stage (Export to Training Sheet)

**Code:**
```python
# Apply dual quality gates
training_pairs = qa_pairs.filter(
  # Quality gate: expert approved
  (col('status') == 'labeled') &
  
  # Governance gate: allowed for training
  (array_contains(col('allowed_uses'), 'training')) &
  (~array_contains(col('prohibited_uses'), 'training'))
)
```

**UI:**
```
Export Summary:
‚úÖ Total Labeled: 100
‚úÖ Training Allowed: 85
‚ö†Ô∏è  Training Prohibited: 15

Exclusion Reasons:
- 12 pairs contain PHI (HIPAA compliance)
- 3 pairs are test set (data hygiene)
```

---

### Example Store (Runtime Few-Shot)

**Code:**
```python
# Only sync approved few-shot examples
few_shot_examples = qa_pairs.filter(
  (col('status') == 'labeled') &
  (array_contains(col('allowed_uses'), 'few_shot')) &
  (~array_contains(col('prohibited_uses'), 'few_shot'))
)
```

**Behavior:**
- Automatically syncs when status changes to `labeled`
- Respects usage constraints
- Excludes PHI, NDA, test set data

---

### Evaluation Harness

**Code:**
```python
# Filter for evaluation-allowed pairs
eval_pairs = qa_pairs.filter(
  (col('status') == 'labeled') &
  (array_contains(col('allowed_uses'), 'evaluation')) &
  (~array_contains(col('prohibited_uses'), 'evaluation'))
)
```

---

## Unity Catalog Integration

Usage constraints can be **automatically inherited** from source table tags:

```python
from databricks.sdk import WorkspaceClient

# Get source table tags
source_table = catalog.get_table('ontos_ml.raw.patient_scans')
tags = source_table.tags

# Auto-populate usage constraints
if 'PII' in tags or 'PHI' in tags:
  qa_pair.prohibited_uses.append('training')
  qa_pair.prohibited_uses.append('validation')
  qa_pair.data_classification = 'restricted'
  qa_pair.usage_reason = f"Source table tagged with {tags} - compliance restriction"
  
if 'CONFIDENTIAL' in tags:
  qa_pair.prohibited_uses.extend(['few_shot', 'evaluation'])
  qa_pair.allowed_uses = ['training', 'validation']
  qa_pair.data_classification = 'confidential'
  qa_pair.usage_reason = "Confidential data - secure pipeline only"
```

**Benefits:**
- Inherit governance rules from source data
- Consistent with existing Unity Catalog governance
- Reduces manual configuration
- Audit trail from source to model

---

## UI/UX Design

### LABEL Stage (Review UI)

**Badges on Q&A Pairs:**
- üü¢ "All Uses Allowed"
- üü° "Training Prohibited - PHI"
- üî¥ "Restricted - Manual Testing Only"
- üîí "Confidential - NDA"

**Constraint Editor:**
```
Usage Constraints:
‚úÖ Few-Shot Examples
‚úÖ Manual Testing
‚úÖ Evaluation
‚ùå Training (prohibited)
‚ùå Validation (prohibited)

Reason: Contains PHI - HIPAA compliance
Classification: Restricted
```

**Expert Actions:**
- View constraints during review
- Modify constraints if needed
- Add justification for changes

---

### TRAIN Stage (Export)

**Before Export:**
```
Training Sheet Export Summary

Total Q&A Pairs: 100
‚îú‚îÄ Approved (labeled): 85
‚îÇ  ‚îú‚îÄ Training Allowed: 70
‚îÇ  ‚îî‚îÄ Training Prohibited: 15
‚îÇ     ‚îú‚îÄ PHI/HIPAA: 12 pairs
‚îÇ     ‚îî‚îÄ Test Set: 3 pairs
‚îî‚îÄ Not Approved: 15
   ‚îú‚îÄ Unlabeled: 10
   ‚îî‚îÄ Rejected: 5

Export will include: 70 pairs
```

**After Export:**
```
‚úÖ Training data exported: 70 pairs
üìä JSONL file: training_sheet_123.jsonl
üìù Only approved, training-allowed pairs included
üîí 15 pairs excluded due to compliance restrictions
```

---

## Audit Trail

All usage constraint changes are logged:

```sql
ontos_ml.workbench.usage_constraint_audit (
  id, qa_pair_id,
  old_allowed_uses ARRAY<STRING>,
  new_allowed_uses ARRAY<STRING>,
  old_prohibited_uses ARRAY<STRING>,
  new_prohibited_uses ARRAY<STRING>,
  old_data_classification STRING,
  new_data_classification STRING,
  reason TEXT,
  modified_by, modified_at
)
```

**Example Queries:**

```sql
-- Who changed this pair's constraints?
SELECT * FROM usage_constraint_audit 
WHERE qa_pair_id = 'qa-123' 
ORDER BY modified_at DESC;

-- What constraints were changed today?
SELECT qa_pair_id, old_prohibited_uses, new_prohibited_uses, reason
FROM usage_constraint_audit
WHERE DATE(modified_at) = CURRENT_DATE();

-- Find pairs that had training prohibited
SELECT * FROM usage_constraint_audit
WHERE NOT array_contains(old_prohibited_uses, 'training')
  AND array_contains(new_prohibited_uses, 'training');
```

---

## Migration Path

### For Existing Q&A Pairs

**Default values for existing data:**
```sql
UPDATE ontos_ml.workbench.qa_pairs
SET 
  allowed_uses = ['training', 'validation', 'evaluation', 'few_shot', 'testing'],
  prohibited_uses = [],
  usage_reason = 'Legacy data - no restrictions applied',
  data_classification = 'internal'
WHERE allowed_uses IS NULL;
```

**For PHI-tagged tables:**
```sql
-- Auto-detect and restrict PHI data
UPDATE ontos_ml.workbench.qa_pairs qa
SET 
  prohibited_uses = ['training', 'validation'],
  allowed_uses = ['few_shot', 'testing', 'evaluation'],
  usage_reason = 'Contains PHI - HIPAA compliance',
  data_classification = 'restricted'
WHERE qa.training_sheet_id IN (
  SELECT ts.id 
  FROM ontos_ml.workbench.training_sheets ts
  JOIN ontos_ml.workbench.sheets s ON s.id = ts.sheet_id
  WHERE s.uc_table_name IN (
    SELECT table_name 
    FROM system.information_schema.table_tags
    WHERE tag_name IN ('PII', 'PHI')
  )
);
```

---

## Benefits

### For Healthcare/Life Sciences
- ‚úÖ HIPAA compliant - PHI not stored in model weights
- ‚úÖ Can still use PHI for few-shot examples (ephemeral)
- ‚úÖ Can measure accuracy on real patient data (evaluation)
- ‚úÖ Audit trail for compliance

### For Financial Services
- ‚úÖ PCI DSS compliant - cardholder data restrictions
- ‚úÖ SOC 2 compliant - data classification tracking
- ‚úÖ Separate production training from testing

### For Legal/Confidential Data
- ‚úÖ NDA enforcement - no client data in examples/logs
- ‚úÖ Trade secret protection - secure pipeline only
- ‚úÖ Audit who accessed what data

### For Data Hygiene
- ‚úÖ Prevent test set contamination
- ‚úÖ Separate train/eval/test properly
- ‚úÖ Track data provenance

---

## Implementation Checklist

### Backend
- [x] Add fields to `qa_pairs` table (`schemas/06_qa_pairs.sql` ‚Äî `allowed_uses`, `prohibited_uses`, `usage_reason`, `data_classification`)
- [ ] Create `usage_constraint_audit` table (not yet implemented)
- [x] Update Q&A pair creation to set default constraints
- [ ] Add Unity Catalog tag detection (auto-detect PII/PHI tags)
- [x] Update TRAIN export filter (dual gates ‚Äî status + governance)
- [ ] Update Example Store sync filter (respects usage constraints)
- [ ] Add constraint validation API

### Frontend
- [x] Add constraint indicators in Q&A pair list (backend model supports it)
- [ ] Add constraint editor UI (no dedicated UI yet)
- [ ] Show export summary with exclusion reasons
- [ ] Add constraint badges in LABEL stage
- [ ] Add audit trail viewer

### Documentation
- [x] PRD updated with usage constraints section
- [x] Real-world examples documented
- [x] Enforcement points defined
- [x] Migration path documented

---

## Next Steps

1. **Review with stakeholders** - Validate scenarios with healthcare/compliance teams
2. **Prototype UI** - Build constraint editor and badges
3. **Backend implementation** - Add fields, filters, audit trail
4. **Unity Catalog integration** - Auto-detect PII/PHI tags
5. **Testing** - Verify dual gates work correctly
6. **Documentation** - User guide for governance features
