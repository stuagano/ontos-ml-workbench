# -----------------------------------------------------------------------------
# Ontos - Environment Configuration
#
# Copy this file to .env and fill in the appropriate values.
# -----------------------------------------------------------------------------

# --- General Application Settings ---
ENV=LOCAL                    # Deployment environment (LOCAL, DEV, PROD)
DEBUG=True                   # Enable debug mode for FastAPI (True/False)
LOG_LEVEL=INFO               # Log level (DEBUG, INFO, WARNING, ERROR)
# LOG_FILE=/path/to/app.log  # Optional: Path to a log file

APP_DEMO_MODE=False          # Enable demo mode (loads sample data on startup) (True/False)
# APP_DB_DROP_ON_START=False # DANGER: Drop and recreate app DB on startup (for dev)
APP_DB_ECHO=False            # Log SQLAlchemy generated SQL statements (True/False)

# --- Databricks Connection (Required for all modes for UC access) ---
DATABRICKS_HOST=https://your-workspace.cloud.databricks.com
# DATABRICKS_TOKEN=dapi123... # Optional: Databricks Personal Access Token.
                             # If not set, SDK will try other auth methods (CLI profile, OAuth).

# --- Databricks Volume for App Data ---
# Required for features like audit logs, data contract outputs, etc.
DATABRICKS_VOLUME=main.default.app_files # Example: <catalog>.<schema>.<volume_name>
APP_AUDIT_LOG_DIR=audit_logs             # Directory within DATABRICKS_VOLUME for audit logs

# --- Database Configuration for Application Metadata ---

POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=ontos_app_user
POSTGRES_PASSWORD=your_secure_postgres_password
POSTGRES_DB=app_ontos
DB_SCHEMA=public # Optional: Schema for app tables in PostgreSQL (defaults to 'public')

# --- Databricks SQL Warehouse for data access (preview tables, reviews, etc.) ---
DATABRICKS_WAREHOUSE_ID=1234567890abcdef
DATABRICKS_HTTP_PATH=/sql/1.0/warehouses/1234567890abcdef

# --- Unity Catalog resources to store app related data ---
DATABRICKS_CATALOG=app_data
DATABRICKS_SCHEMA=app_ontos
DATABRICKS_VOLUME=app_files

# --- Role-Based Access Control (RBAC) ---
# Comma-separated list of Databricks group names to assign the default 'Admin' role upon first startup.
# Example: APP_ADMIN_DEFAULT_GROUPS="admins,workspace-power-users"
APP_ADMIN_DEFAULT_GROUPS="admins"

# --- Optional: Git Integration for Configuration Backup/Sync ---
# GIT_REPO_URL=https://github.com/your_user/your_repo.git
# GIT_BRANCH=main
# GIT_USERNAME=your_git_username
# GIT_PASSWORD=your_git_password_or_pat # Or Personal Access Token

# --- Optional: Workspace Path for Job Tasks (Local Dev with Remote Jobs) ---
# When running locally but creating jobs that run in the workspace, set this to
# the workspace path where app files are deployed. If not set, will derive from
# __file__ path (works when app runs in workspace).
# Example: WORKSPACE_APP_PATH=/Workspace/Users/user@domain.com/app-name/src/backend/src
# WORKSPACE_APP_PATH=

# --- Optional: Workspace Deployment Path for Containerized Apps ---
# When deployed as a Databricks App (containerized), job tasks cannot access the
# container filesystem. Set this to specify where workflow code should be deployed
# in the workspace. The JobsManager will copy workflow folders here before creating jobs.
# Example: WORKSPACE_DEPLOYMENT_PATH=/Workspace/Users/user@domain.com/ontos-workflows
# If not set, falls back to WORKSPACE_APP_PATH or __file__ derivation (legacy behavior)
# WORKSPACE_DEPLOYMENT_PATH=

# --- Optional: LLM/AI Features Configuration ---
# Enable or disable AI-powered features (e.g., asset content analysis in Data Asset Reviews)
LLM_ENABLED=False

# Databricks Model Serving endpoint name (required if LLM_ENABLED=True)
# This is the MODEL NAME ONLY, not a full URL
# When deployed as Databricks App, this is set automatically via Apps environment configuration
# Example: LLM_ENDPOINT=databricks-claude-3-7-sonnet
# LLM_ENDPOINT=

# Databricks base URL for serving endpoints (optional, auto-derived from DATABRICKS_HOST)
# If not set, the base URL is automatically constructed as: {DATABRICKS_HOST}/serving-endpoints
# Only set this if you need to override the default behavior
# Example: LLM_BASE_URL=https://your-workspace.cloud.databricks.com/serving-endpoints
# LLM_BASE_URL=

# Authentication:
# - In Databricks Apps: Uses per-user token from x-forwarded-access-token header (automatic)
# - In local dev: Uses DATABRICKS_TOKEN from this file (must be set above)

# Custom system prompt for AI analysis (Data Steward role)
# If not set, uses a default prompt for PII/sensitive data detection
# LLM_SYSTEM_PROMPT="You are a Data Steward..."

# Disclaimer text shown to users before using AI features
# LLM_DISCLAIMER_TEXT="This feature uses AI to analyze data assets. AI-generated content may contain errors. Review all suggestions carefully before taking action."

# Security: First-phase injection detection prompt (advanced - usually not changed)
# LLM_INJECTION_CHECK_PROMPT="You are a security analyzer. Analyze the following content..."

# --- Self-Service Sandbox Policy Settings ---
# These settings control which catalogs and schemas users can create objects in
# via the self-service dialog. This is a global security boundary separate from
# role-based deployment policies.

# Default schema name for sandbox operations
# SANDBOX_DEFAULT_SCHEMA=sandbox

# Catalog prefixes allowed for self-service creation (JSON array format)
# Users can create objects in catalogs starting with these prefixes
# SANDBOX_ALLOWED_CATALOG_PREFIXES=["user_"]

# Explicit catalog names allowed for self-service creation (JSON array format)
# SANDBOX_ALLOWED_CATALOGS=[]

# Schema names allowed for self-service creation (JSON array format)
# SANDBOX_ALLOWED_SCHEMAS=["sandbox"]

# Enable/disable sandbox allowlist enforcement
# Set to False to disable sandbox restrictions entirely (allows any catalog/schema)
# SANDBOX_ENFORCE_ALLOWLIST=True
