"""Pydantic models for AssembledDataset - materialized prompt/response pairs.

Following GCP Vertex AI pattern:
- assembly_table, assembly = dataset.assemble(template_config)
- The assembly is the concrete result of applying the template to the dataset
- Contains actual rendered prompts and responses ready for labeling/training
"""

from datetime import datetime
from enum import Enum
from typing import Any

from pydantic import BaseModel, Field

from app.models.sheet import TemplateConfig


class AssemblyStatus(str, Enum):
    """Assembly lifecycle status."""

    ASSEMBLING = "assembling"  # Currently being assembled
    READY = "ready"  # Assembly complete, ready for use
    FAILED = "failed"  # Assembly failed
    ARCHIVED = "archived"


class ResponseSource(str, Enum):
    """Source of the response value."""

    EMPTY = "empty"  # No response yet
    AI_GENERATED = "ai_generated"  # Generated by AI
    HUMAN_LABELED = "human_labeled"  # Labeled by human
    HUMAN_VERIFIED = "human_verified"  # AI-generated but verified/corrected by human


class AssembledRow(BaseModel):
    """A single assembled row with rendered prompt and response."""

    row_index: int = Field(..., description="Index into the source sheet")

    # The actual rendered prompt (template + data merged)
    prompt: str = Field(..., description="Fully rendered prompt with data substituted")

    # Source data snapshot (for reference/debugging)
    source_data: dict[str, Any] = Field(
        default_factory=dict,
        description="Snapshot of source column values used to render the prompt",
    )

    # Response
    response: str | None = Field(
        default=None,
        description="The response value (AI-generated or human-labeled)",
    )
    response_source: ResponseSource = Field(
        default=ResponseSource.EMPTY,
        description="How the response was produced",
    )

    # Metadata
    generated_at: datetime | None = None
    labeled_at: datetime | None = None
    labeled_by: str | None = None
    verified_at: datetime | None = None
    verified_by: str | None = None

    # Quality flags
    is_flagged: bool = Field(default=False, description="Flagged for review")
    flag_reason: str | None = None
    confidence_score: float | None = Field(
        default=None, ge=0, le=1, description="AI confidence in the response"
    )


class AssembledDataset(BaseModel):
    """
    Materialized result of applying a template to a sheet.

    This is the concrete output of sheet.assemble() - actual prompt/response pairs
    that can be used for labeling, review, and fine-tuning export.
    """

    id: str

    # Source references
    sheet_id: str = Field(..., description="ID of the source sheet")
    sheet_name: str | None = Field(
        default=None, description="Name of source sheet at assembly time"
    )

    # Frozen template config (snapshot at assembly time)
    template_config: TemplateConfig = Field(
        ..., description="Snapshot of template config used for this assembly"
    )

    # Assembly metadata
    status: AssemblyStatus = AssemblyStatus.ASSEMBLING
    total_rows: int = Field(default=0, description="Total number of assembled rows")

    # Statistics
    ai_generated_count: int = Field(
        default=0, description="Rows with AI-generated responses"
    )
    human_labeled_count: int = Field(default=0, description="Rows with human labels")
    human_verified_count: int = Field(default=0, description="Rows verified by humans")
    flagged_count: int = Field(default=0, description="Rows flagged for review")

    # Timestamps
    created_at: datetime | None = None
    created_by: str | None = None
    updated_at: datetime | None = None
    completed_at: datetime | None = None  # When assembly finished

    # Error info (if status == FAILED)
    error_message: str | None = None

    class Config:
        from_attributes = True


# ============================================================================
# Request/Response Models
# ============================================================================


class AssembleRequest(BaseModel):
    """Request body for assembling a sheet."""

    # Optional: override the sheet's attached template
    template_config: TemplateConfig | None = Field(
        default=None,
        description="Optional template override. If not provided, uses sheet's attached template.",
    )

    # Options
    row_limit: int | None = Field(
        default=None,
        ge=1,
        le=100000,
        description="Limit number of rows to assemble (for preview/testing)",
    )
    generate_responses: bool = Field(
        default=False,
        description="If True, also run AI generation on assembled rows",
    )


class AssembleResponse(BaseModel):
    """Response from assembly operation."""

    assembly_id: str
    sheet_id: str
    status: AssemblyStatus
    total_rows: int
    message: str | None = None


class AssemblyPreviewResponse(BaseModel):
    """Response for previewing assembled rows."""

    assembly_id: str
    rows: list[AssembledRow]
    total_rows: int
    preview_rows: int

    # Stats
    ai_generated_count: int
    human_labeled_count: int
    human_verified_count: int
    flagged_count: int


class AssemblyRowUpdate(BaseModel):
    """Request to update a single assembled row."""

    response: str | None = Field(default=None, description="New response value")
    is_flagged: bool | None = Field(default=None, description="Flag for review")
    flag_reason: str | None = Field(default=None, description="Reason for flagging")


class AssemblyGenerateRequest(BaseModel):
    """Request to generate AI responses for assembled rows."""

    row_indices: list[int] | None = Field(
        default=None,
        description="Specific rows to generate. If None, generates all empty rows.",
    )
    overwrite_existing: bool = Field(
        default=False,
        description="If True, regenerate even if response exists",
    )
    include_examples: bool = Field(
        default=True,
        description="Include human-labeled rows as few-shot examples",
    )


class AssemblyGenerateResponse(BaseModel):
    """Response from AI generation on assembly."""

    assembly_id: str
    generated_count: int
    failed_count: int
    errors: list[dict[str, Any]] | None = None


class AssemblyExportRequest(BaseModel):
    """Request to export assembly for fine-tuning."""

    # Export destination
    volume_path: str = Field(
        ...,
        description="UC Volume path for JSONL output (e.g., /Volumes/catalog/schema/vol/data.jsonl)",
    )

    # Filter options
    include_sources: list[ResponseSource] | None = Field(
        default=None,
        description="Only include rows with these response sources. Default: human_labeled, human_verified",
    )
    exclude_flagged: bool = Field(
        default=True,
        description="Exclude flagged rows from export",
    )

    # Format options
    include_system_instruction: bool = Field(
        default=True,
        description="Include system instruction in training examples",
    )
    format: str = Field(
        default="openai_chat",
        description="Export format: openai_chat, anthropic, or gemini",
    )


class AssemblyExportResponse(BaseModel):
    """Response from export operation."""

    assembly_id: str
    volume_path: str
    examples_exported: int
    format: str
    excluded_count: int = Field(default=0, description="Rows excluded due to filters")


class AssemblyListResponse(BaseModel):
    """Response for listing assemblies."""

    assemblies: list[AssembledDataset]
    total: int
    page: int
    page_size: int
